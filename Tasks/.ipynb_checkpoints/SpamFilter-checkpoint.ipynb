{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import nltk\n",
    "import pymorphy2\n",
    "from nltk.corpus import stopwords\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise = [',', '.', ':', '?', '«', '»', '-', '(', ')', '!', '\\'', \"—\", ';', \"”\", \"...\", \"\\'\\'\", \"/**//**/\", \"“\", \"„\", \"–\"]\n",
    "\n",
    "\n",
    "def get_normal_form(text):\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    analyzer = pymorphy2.MorphAnalyzer()\n",
    "    normalized_words = []\n",
    "    for token in tokens:\n",
    "        if token in string.punctuation: continue\n",
    "        if token in noise: continue\n",
    "        normalized_words.append(analyzer.parse(token)[0].normal_form)\n",
    "    return normalized_words\n",
    "\n",
    "\n",
    "def remove_stopwords(word_tokens):\n",
    "    stop_words = set(stopwords.words('russian'))\n",
    "    filtered_sentences = [w for w in word_tokens if not w in stop_words]\n",
    "    return filtered_sentences\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "spam = ['Путевки по низкой цене!', \\\n",
    "        'Акция! Купи шоколадку и получи телефон в подарок.']\n",
    "inf = ['Завтра состоится собрание.',\\\n",
    "      'Купи килограмм яблок и шоколадку']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['путёвка', 'низка', 'цена'],\n",
       " ['акция', 'купить', 'шоколадка', 'получить', 'телефон', 'подарок']]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def make_dict(list_):\n",
    "    normal__forms = []\n",
    "    for text in list_:\n",
    "        form = remove_stopwords(get_normal_form(text))\n",
    "        normal__forms += [form]\n",
    "    return normal__forms\n",
    "\n",
    "make_dict(spam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[['путёвка', 'низка', 'цена'], 0], [['акция', 'купить', 'шоколадка', 'получить', 'телефон', 'подарок'], 0], [['завтра', 'состояться', 'собрание'], 1], [['купить', 'килограмм', 'яблоко', 'шоколадка'], 1]]\n"
     ]
    }
   ],
   "source": [
    "def mark_texts(texts, mark):\n",
    "    return [[item, mark] for item in make_dict(texts)]\n",
    "\n",
    "\n",
    "dataset = []\n",
    "dataset += mark_texts(spam, 0)\n",
    "dataset += mark_texts(inf, 1)\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier: \n",
      "({0: 0.5, 1: 0.5}, {(0, 'путёвка'): 0.3333333333333333, (0, 'низка'): 0.3333333333333333, (0, 'цена'): 0.3333333333333333, (0, 'акция'): 0.3333333333333333, (0, 'купить'): 0.3333333333333333, (0, 'шоколадка'): 0.3333333333333333, (0, 'получить'): 0.3333333333333333, (0, 'телефон'): 0.3333333333333333, (0, 'подарок'): 0.3333333333333333, (1, 'завтра'): 0.3333333333333333, (1, 'состояться'): 0.3333333333333333, (1, 'собрание'): 0.3333333333333333, (1, 'купить'): 0.3333333333333333, (1, 'килограмм'): 0.3333333333333333, (1, 'яблоко'): 0.3333333333333333, (1, 'шоколадка'): 0.3333333333333333})\n"
     ]
    }
   ],
   "source": [
    "def train(dataset, alpha):\n",
    "    classes, freq, total = {}, {}, set()\n",
    "    for features, label in dataset:\n",
    "        if label not in classes:\n",
    "            classes[label] = 0\n",
    "        classes[label] += 1\n",
    "        for feature in features:\n",
    "            if (label,feature) not in freq:\n",
    "                freq[(label,feature)] = 0\n",
    "            freq[(label,feature)] += 1\n",
    "        total.add(tuple(feature))\n",
    "            \n",
    "    for label, feature in freq:\n",
    "        freq[(label,feature)] = (alpha + freq[(label,feature)]) / \\\n",
    "        (alpha*len(total) + classes[label])\n",
    "    for c in classes:\n",
    "        classes[c] /= len(dataset)\n",
    "        \n",
    "    return classes, freq \n",
    "\n",
    "\n",
    "def classify(classifier, features):\n",
    "    classes, freq = classifier\n",
    "    return max(classes.keys(), \\\n",
    "              key = lambda cl: np.log10(classes[cl]) + \\\n",
    "              sum(np.log10(freq.get((cl,feature), 10**(-7))) for \\\n",
    "                 feature in features))\n",
    "\n",
    "\n",
    "classifier = train(dataset, 1)\n",
    "print('Classifier: ', classifier, sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result: 1\n",
      "Classifier after loading from .pkl:\n",
      "({0: 0.5, 1: 0.5}, {(0, 'путёвка'): 0.3333333333333333, (0, 'низка'): 0.3333333333333333, (0, 'цена'): 0.3333333333333333, (0, 'акция'): 0.3333333333333333, (0, 'купить'): 0.3333333333333333, (0, 'шоколадка'): 0.3333333333333333, (0, 'получить'): 0.3333333333333333, (0, 'телефон'): 0.3333333333333333, (0, 'подарок'): 0.3333333333333333, (1, 'завтра'): 0.3333333333333333, (1, 'состояться'): 0.3333333333333333, (1, 'собрание'): 0.3333333333333333, (1, 'купить'): 0.3333333333333333, (1, 'килограмм'): 0.3333333333333333, (1, 'яблоко'): 0.3333333333333333, (1, 'шоколадка'): 0.3333333333333333})\n",
      "Result after: 1\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "\n",
    "test = ['В магазине гора яблок. Купи семь килограмм и шоколадку.']\n",
    "\n",
    "print('Result:', classify(classifier, make_dict(test)[0]))\n",
    "\n",
    "joblib.dump(classifier, 'res/dicts.pkl')\n",
    "classifier = joblib.load('res/dicts.pkl')\n",
    "print('Classifier after loading from .pkl:', classifier, sep='\\n')\n",
    "print('Result after:', classify(classifier, make_dict(test)[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
